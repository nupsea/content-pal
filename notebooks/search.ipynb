{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c098c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee928d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "\n",
    "RET = {\n",
    "    \"embedder\": \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\",  # 384-dim, fast, good for short queries\n",
    "\n",
    "    # Candidate generation\n",
    "    \"bm25_size\": 250,     # number of BM25 candidates pulled from OS\n",
    "    \"top_k\": 10,          # final results you return to chat\n",
    "\n",
    "    # Client-side re-rank: final = alpha * bm25_norm + (1 - alpha) * cosine\n",
    "    \"alpha\": 0.65,        # sweep 0.55–0.75 on your eval later\n",
    "\n",
    "    # Tiny, generic expansions (LLM-free)\n",
    "    \"expand\": True,\n",
    "\n",
    "    # BM25 dis_max buckets (generic + safe)\n",
    "    \"bm25\": {\n",
    "        \"tie_breaker\": 0.10,\n",
    "        \"boosts\": {\n",
    "            \"title_phrase\": 12.0,\n",
    "            \"cast_phrase\":   8.0,\n",
    "            \"title_best\":   10.0,\n",
    "            \"cast_best\":     7.0,\n",
    "            \"director\":      2.5,\n",
    "            \"listed_in\":     9.0,   # genres/audience — biggest ROI on your data\n",
    "            \"country\":       4.0,   # e.g., “german series”\n",
    "            \"rating\":        2.5,   # e.g., “mature/TV-MA”\n",
    "            \"type\":          1.5,   # small nudge\n",
    "            \"desc_phrase\":   1.05   # description only as phrase; avoid dominance\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed620fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping & util\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "_DATE_PATTERNS = [\n",
    "    \"%Y-%m-%d\",        # 2021-09-25\n",
    "    \"%B %d, %Y\",       # September 25, 2021\n",
    "    \"%b %d, %Y\",       # Sep 25, 2021\n",
    "    \"%B %d %Y\",        # September 25 2021 (no comma)\n",
    "    \"%b %d %Y\",        # Sep 25 2021 (no comma)\n",
    "]\n",
    "\n",
    "def to_iso_date(s: str | None) -> str | None:\n",
    "    if not s:\n",
    "        return None\n",
    "    s2 = str(s).strip()\n",
    "    for fmt in _DATE_PATTERNS:\n",
    "        try:\n",
    "            return datetime.strptime(s2, fmt).date().isoformat()\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def add_text_copies_mapping(client, index):\n",
    "    body = {\"properties\": {\n",
    "        \"listed_in_text\": {\"type\": \"text\"},\n",
    "        \"country_text\":   {\"type\": \"text\"},\n",
    "        \"rating_text\":    {\"type\": \"text\"},\n",
    "        \"type_text\":      {\"type\": \"text\"},\n",
    "        \"date_added\":     {\"type\": \"date\"},\n",
    "        \"date_added_raw\": {\"type\": \"keyword\"},\n",
    "    }}\n",
    "    client.indices.put_mapping(index=index, body=body, ignore=400)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ccfb6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing\n",
    "\n",
    "import re\n",
    "\n",
    "def _clean(s):\n",
    "    if s is None: return None\n",
    "    s2 = str(s).strip()\n",
    "    return s2 or None\n",
    "\n",
    "def _split_csv(s):\n",
    "    s = _clean(s)\n",
    "    return [p.strip() for p in s.split(\",\")] if s else []\n",
    "\n",
    "def row_normalize(row: dict) -> dict:\n",
    "    listed = _split_csv(row.get(\"listed_in\"))\n",
    "    cast_list = _split_csv(row.get(\"cast\"))\n",
    "    ry = _clean(row.get(\"release_year\"))\n",
    "    release_year = int(ry) if ry and ry.isdigit() else None\n",
    "    \n",
    "    raw_date = _clean(row.get(\"date_added\"))\n",
    "    iso_date = to_iso_date(raw_date)\n",
    "\n",
    "    doc = {\n",
    "        \"show_id\": _clean(row.get(\"show_id\")),\n",
    "        \"type\": _clean(row.get(\"type\")),\n",
    "        \"type_text\": _clean(row.get(\"type\")),\n",
    "        \"title\": _clean(row.get(\"title\")),\n",
    "        \"director\": _clean(row.get(\"director\")),\n",
    "        \"cast\": _clean(row.get(\"cast\")),\n",
    "        \"cast_list\": cast_list,\n",
    "        \"country\": _clean(row.get(\"country\")),\n",
    "        \"country_text\": _clean(row.get(\"country\")),\n",
    "        \"release_year\": release_year,\n",
    "        \"rating\": _clean(row.get(\"rating\")),\n",
    "        \"rating_text\": _clean(row.get(\"rating\")),\n",
    "        \"duration\": _clean(row.get(\"duration\")),\n",
    "        \"listed_in\": listed,\n",
    "        \"listed_in_text\": \", \".join(listed) if listed else None,\n",
    "        \"description\": _clean(row.get(\"description\")),\n",
    "        \"date_added_raw\": raw_date,     \n",
    "        # only set date_added if we could parse it\n",
    "        **({\"date_added\": iso_date} if iso_date else {}),\n",
    "    }\n",
    "    # drop empties\n",
    "    doc = {k: v for k, v in doc.items() if v not in (None, \"\", [], {})}\n",
    "    doc[\"_id\"] = doc.get(\"show_id\") or (re.sub(r\"\\s+\", \"\", (doc.get(\"title\") or \"\").lower()) + \"_gen\")\n",
    "    return doc\n",
    "\n",
    "def text_for_embedding(d: dict) -> str:\n",
    "    # Add light categorical cues so semantics “hear” audience/country/rating\n",
    "    parts = []\n",
    "    for k in (\"title\",\"description\",\"director\",\"type\",\"country\",\"rating\"):\n",
    "        v = d.get(k); parts.append(v) if v else None\n",
    "    if d.get(\"cast_list\"): parts.append(\", \".join(d[\"cast_list\"]))\n",
    "    if d.get(\"listed_in\"): parts.append(\", \".join(d[\"listed_in\"]))\n",
    "    return \" | \".join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "795ebf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate generation (BM25-only)\n",
    "\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def get_embed_model(name: str):\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    return SentenceTransformer(name)  # used later in re-rank\n",
    "\n",
    "def _normalize_expand(q: str, enable=True) -> str:\n",
    "    qn = q.lower().strip().replace(\"sci-fi\",\"sci fi\").replace(\"&\",\" and \")\n",
    "    if not enable: return qn\n",
    "    adds = []\n",
    "    if \"kids\" in qn or \"family\" in qn: adds += [\"children\",\"preschool\",\"toddler\",\"family\"]\n",
    "    if any(t in qn for t in (\"romantic\",\"romance\",\"romcom\")): adds += [\"love\",\"relationships\",\"romcom\"]\n",
    "    if any(t in qn for t in (\"mature\",\"adult\")): adds += [\"tv ma\",\"r\",\"mature\"]\n",
    "    if any(t in qn for t in (\"series\",\" tv \",\" tv-\",\" tv_\",\" show\")): adds += [\"tv show\",\"series\"]\n",
    "    for hint,country in [(\"german\",\"germany\"),(\"korean\",\"south korea\"),(\"japanese\",\"japan\"),\n",
    "                         (\"french\",\"france\"),(\"spanish\",\"spain\"),(\"italian\",\"italy\")]:\n",
    "        if hint in qn: adds.append(country)\n",
    "    return qn + (\" \" + \" \".join(adds) if adds else \"\")\n",
    "\n",
    "def bm25_query(qn: str, boosts: dict, tie: float) -> dict:\n",
    "    return {\n",
    "      \"dis_max\": {\n",
    "        \"tie_breaker\": tie,\n",
    "        \"queries\": [\n",
    "          {\"multi_match\": {\"query\": qn, \"type\": \"phrase\",\n",
    "                           \"fields\": [f\"title^{boosts['title_phrase']}\", f\"cast^{boosts['cast_phrase']}\"], \"slop\": 1}},\n",
    "          {\"multi_match\": {\"query\": qn, \"type\": \"best_fields\",\n",
    "                           \"fields\": [f\"title^{boosts['title_best']}\", f\"cast^{boosts['cast_best']}\", f\"director^{boosts['director']}\"],\n",
    "                           \"operator\": \"AND\", \"minimum_should_match\": \"2<-25%\"}},\n",
    "          {\"multi_match\": {\"query\": qn, \"type\": \"best_fields\",\n",
    "                           \"fields\": [f\"listed_in_text^{boosts['listed_in']}\"], \"operator\": \"OR\"}},\n",
    "          {\"multi_match\": {\"query\": qn, \"type\": \"best_fields\",\n",
    "                           \"fields\": [f\"country_text^{boosts['country']}\", f\"rating_text^{boosts['rating']}\", f\"type_text^{boosts['type']}\"]}},\n",
    "          {\"match_bool_prefix\": {\"title\": {\"query\": qn, \"boost\": 2.0}}},\n",
    "          {\"match_bool_prefix\": {\"cast\":  {\"query\": qn, \"boost\": 1.5}}},\n",
    "          {\"match_phrase\": {\"description\": {\"query\": qn, \"slop\": 2, \"boost\": boosts[\"desc_phrase\"]}}}\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "\n",
    "def bm25_candidates(client, index, q, *, cfg=RET):\n",
    "    qn = _normalize_expand(q, cfg[\"expand\"])\n",
    "    bq = bm25_query(qn, cfg[\"bm25\"][\"boosts\"], cfg[\"bm25\"][\"tie_breaker\"])\n",
    "    body = {\n",
    "        \"size\": cfg[\"bm25_size\"],\n",
    "        \"_source\": [\"show_id\",\"title\",\"type\",\"release_year\",\"vector\"],  # include vector for re-rank\n",
    "        \"query\": bq\n",
    "    }\n",
    "    return client.search(index=index, body=body)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c55e2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client-side semantic re-rank\n",
    "\n",
    "\n",
    "import math\n",
    "\n",
    "def _minmax(scores):\n",
    "    if not scores: return ([], 0.0, 1.0)\n",
    "    lo, hi = min(scores), max(scores)\n",
    "    if math.isclose(hi, lo): return ([1.0]*len(scores), lo, hi)\n",
    "    return ([(s - lo)/(hi - lo) for s in scores], lo, hi)\n",
    "\n",
    "def rerank_with_vectors(res, qvec, *, alpha=0.65, top_k=10):\n",
    "    hits = res.get(\"hits\",{}).get(\"hits\",[])\n",
    "    if not hits: return []\n",
    "    bm25_scores = [h.get(\"_score\", 0.0) for h in hits]\n",
    "    bm25_norm, _, _ = _minmax(bm25_scores)\n",
    "\n",
    "    ranked = []\n",
    "    for h, b in zip(hits, bm25_norm):\n",
    "        v = h.get(\"_source\",{}).get(\"vector\")\n",
    "        if not v:\n",
    "            final = alpha * b\n",
    "        else:\n",
    "            # if you indexed normalized vectors (recommended), dot == cosine\n",
    "            cos = sum(a*b2 for a,b2 in zip(qvec, v))\n",
    "            final = alpha * b + (1.0 - alpha) * cos\n",
    "        ranked.append((final, h))\n",
    "\n",
    "    ranked.sort(key=lambda x: x[0], reverse=True)\n",
    "    return [h for _, h in ranked[:top_k]]\n",
    "\n",
    "def retrieve(client, index, q, *, cfg=RET, model=None):\n",
    "    res = bm25_candidates(client, index, q, cfg=cfg)\n",
    "    m = model or get_embed_model(cfg[\"embedder\"])\n",
    "    qvec = m.encode(q, normalize_embeddings=True).tolist()\n",
    "    return rerank_with_vectors(res, qvec, alpha=cfg[\"alpha\"], top_k=cfg[\"top_k\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4d6f6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate \n",
    "\n",
    "def ids_from_hits(hits): return [h[\"_source\"].get(\"show_id\",\"\") for h in hits]\n",
    "\n",
    "def hit_rate_at_k(ids, gold, k=10): return 1.0 if gold in ids[:k] else 0.0\n",
    "def mrr_at_k(ids, gold, k=10):\n",
    "    for i,x in enumerate(ids[:k], 1):\n",
    "        if x == gold: return 1.0 / i\n",
    "    return 0.0\n",
    "\n",
    "def evaluate(client, index, qid_to_queries: dict, *, cfg=RET):\n",
    "    total_hr = total_mrr = n = 0\n",
    "    for gold, qs in qid_to_queries.items():\n",
    "        for q in qs:\n",
    "            hits = retrieve(client, index, q, cfg=cfg)\n",
    "            ids  = ids_from_hits(hits)\n",
    "            total_hr  += hit_rate_at_k(ids, gold, cfg[\"top_k\"])\n",
    "            total_mrr += mrr_at_k(ids, gold, cfg[\"top_k\"])\n",
    "            n += 1\n",
    "    return {\"hit_rate\": total_hr / max(1,n), \"mrr\": total_mrr / max(1,n)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde1a486",
   "metadata": {},
   "source": [
    "### Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97501666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering 7370 ASCII-only rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Internal Catalog Data Load \n",
    "csv_path = os.getcwd() + '/../data/netflix_titles.csv'\n",
    "\n",
    "ascii_only = re.compile(r'^[\\x00-\\x7F]+$')\n",
    "\n",
    "def is_ascii(s):\n",
    "    return bool(s) and ascii_only.match(s)\n",
    "\n",
    "with open(csv_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    data = [\n",
    "        row for row in reader\n",
    "        if is_ascii(row.get(\"title\", \"\").strip()) and is_ascii(row.get(\"description\", \"\").strip())\n",
    "    ]\n",
    "\n",
    "print(f\"Considering {len(data)} ASCII-only rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3d81351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "ground_truth = []\n",
    "\n",
    "with open('results.json', 'r') as f:\n",
    "    results = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "256c61be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s1426': ['documentary',\n",
       "  'chess movie',\n",
       "  'story about a chess prodigy',\n",
       "  \"making of The Queen's Gambit documentary\",\n",
       "  'behind the scenes of a chess film'],\n",
       " 's7321': ['Goth',\n",
       "  'independent movie',\n",
       "  'film about faith and family',\n",
       "  \"comedy drama about a nun's journey\",\n",
       "  'movies featuring characters returning home from war']}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get two records from dict\n",
    "sample_results = {k: results[k] for k in list(results)[:2]}\n",
    "sample_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f26b878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "ground_truth = []\n",
    "\n",
    "with open('results.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "\n",
    "for s_id, qs in results.items():\n",
    "    for q in qs:\n",
    "        ground_truth.append({'query': q, 'doc_id': s_id})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87821b86",
   "metadata": {},
   "source": [
    "### OpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc474185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os, re\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from itertools import islice\n",
    "from typing import Any, Dict, Iterable, Iterator, List, Optional, Sequence, Tuple\n",
    "\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from opensearchpy.helpers import streaming_bulk\n",
    "\n",
    "# Lazy import for speed if embed=False\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer  # type: ignore\n",
    "except Exception:\n",
    "    SentenceTransformer = None  # noqa: N816"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7665f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenSearch Config \n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Cfg:\n",
    "    embed_model: str = os.getenv(\"EMBED_MODEL\", \"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    embed_batch: int = int(os.getenv(\"EMBED_BATCH\", \"32\"))\n",
    "    index: str = os.getenv(\"OS_INDEX\", \"netflix_assets\")\n",
    "    vector_dim: int = int(os.getenv(\"OS_VECTOR_DIM\", \"384\"))\n",
    "    url: str = os.getenv(\"OPENSEARCH_URL\", \"https://localhost:9200\")\n",
    "    user: str = os.getenv(\"OS_USER\", \"admin\")\n",
    "    pwd: str = os.getenv(\"OS_PASS\", \"admin\")\n",
    "    verify: bool = os.getenv(\"OS_VERIFY\", \"true\").lower() in (\"true\", \"1\", \"yes\")\n",
    "    timeout: int = int(os.getenv(\"OS_TIMEOUT\", \"60\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "abcfcaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- OpenSearch + Embedding --------------------\n",
    "\n",
    "def make_client(cfg: Cfg) -> OpenSearch:\n",
    "    if cfg.url.startswith(\"https://\"):\n",
    "        return OpenSearch(\n",
    "            cfg.url,\n",
    "            http_auth=(cfg.user, cfg.pwd),\n",
    "            verify_certs=cfg.verify,\n",
    "            ssl_assert_hostname=cfg.verify,\n",
    "            ssl_show_warn=cfg.verify,\n",
    "            http_compress=True,\n",
    "            connection_class=RequestsHttpConnection,\n",
    "            timeout=cfg.timeout, max_retries=3, retry_on_timeout=True,\n",
    "        )\n",
    "    return OpenSearch(cfg.url, http_compress=True, timeout=cfg.timeout, max_retries=3, retry_on_timeout=True)\n",
    "\n",
    "_embedder_cache: Dict[str, Any] = {}\n",
    "\n",
    "def get_embedder(cfg: Cfg):\n",
    "    if SentenceTransformer is None:\n",
    "        raise RuntimeError(\"sentence-transformers not installed, but embed=True requested.\")\n",
    "    key = cfg.embed_model\n",
    "    emb = _embedder_cache.get(key)\n",
    "    if emb is None:\n",
    "        model = SentenceTransformer(cfg.embed_model)\n",
    "        # quick dim probe (no hard fail in prod unless you want fail-fast)\n",
    "        try:\n",
    "            v = model.encode([\"dim\"], normalize_embeddings=True)\n",
    "            dim = v.shape[1] if hasattr(v, \"shape\") else len(v[0])\n",
    "            if dim != cfg.vector_dim:\n",
    "                raise RuntimeError(f\"VECTOR_DIM={cfg.vector_dim} mismatches model dim={dim}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        _embedder_cache[key] = model\n",
    "        emb = model\n",
    "    return emb\n",
    "\n",
    "def ensure_index(client: OpenSearch, cfg: Cfg) -> None:\n",
    "    try:\n",
    "        exists = client.indices.exists(index=cfg.index)\n",
    "    except TypeError:  # old clients sig\n",
    "        exists = client.indices.exists(cfg.index)\n",
    "    if not (exists if isinstance(exists, bool) else exists):\n",
    "        client.indices.create(index=cfg.index, body=index_mapping(cfg.vector_dim), ignore=400)\n",
    "        print(f\"created index {cfg.index}\")\n",
    "    else:\n",
    "        print(f\"using index {cfg.index}\")\n",
    "    client.indices.refresh(index=cfg.index)\n",
    "\n",
    "\n",
    "# -------------------- Action stream --------------------\n",
    "\n",
    "def actions_from_rows(\n",
    "    rows: Iterable[Dict[str, str]],\n",
    "    cfg: Cfg,\n",
    "    embed: bool = True,\n",
    "    embedder=None,\n",
    ") -> Iterator[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Yields bulk index actions. When embed=True, encodes in efficient batches.\n",
    "    \"\"\"\n",
    "    if not embed:\n",
    "        for r in rows:\n",
    "            d = row_normalize(r)\n",
    "            _id = d.get(\"_id\")\n",
    "            if not _id:\n",
    "                continue\n",
    "            src = {k: v for k, v in d.items() if k != \"_id\"}\n",
    "            yield {\"_op_type\": \"index\", \"_index\": cfg.index, \"_id\": _id, **src}\n",
    "        return\n",
    "\n",
    "    model = embedder or get_embedder(cfg)\n",
    "    norm = (row_normalize(r) for r in rows)\n",
    "\n",
    "    for chunk in _batched(norm, cfg.embed_batch):\n",
    "        docs = [d for d in chunk if d.get(\"_id\")]\n",
    "        if not docs:\n",
    "            continue\n",
    "        texts = [text_for_embedding(d) for d in docs]\n",
    "        vecs = model.encode(\n",
    "            texts,\n",
    "            normalize_embeddings=True,\n",
    "            batch_size=cfg.embed_batch,\n",
    "            convert_to_numpy=True,\n",
    "            show_progress_bar=False,\n",
    "        )\n",
    "        # Avoid numpy -> list per element call overhead by one pass\n",
    "        for d, v in zip(docs, vecs.tolist() if hasattr(vecs, \"tolist\") else vecs):\n",
    "            _id = d[\"_id\"]\n",
    "            src = {k: v2 for k, v2 in d.items() if k != \"_id\"}\n",
    "            src[\"vector\"] = v if isinstance(v, list) else list(v)\n",
    "            yield {\"_op_type\": \"index\", \"_index\": cfg.index, \"_id\": _id, **src}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82958537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "\n",
    "def _batched(it: Iterable[Any], n: int) -> Iterator[List[Any]]:\n",
    "    it = iter(it)\n",
    "    while True:\n",
    "        chunk = list(islice(it, n))\n",
    "        if not chunk: return\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1d864e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using index netflix_assets\n"
     ]
    }
   ],
   "source": [
    "cfg = Cfg()\n",
    "os_client = make_client(cfg)\n",
    "ensure_index(os_client, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6841a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulk indexed 7370 documents into netflix_assets\n"
     ]
    }
   ],
   "source": [
    "from opensearchpy.helpers import streaming_bulk\n",
    "\n",
    "success = 0\n",
    "for ok, item in streaming_bulk(\n",
    "    client=os_client,\n",
    "    actions=actions_from_rows(data, cfg, embed=True),\n",
    "    chunk_size=cfg.embed_batch,          # good default: your embed batch\n",
    "    max_retries=3,\n",
    "    raise_on_error=False,                 # don't raise on first bad doc\n",
    "    request_timeout=cfg.timeout,\n",
    "):\n",
    "    if ok:\n",
    "        success += 1\n",
    "    else:\n",
    "        # optional: log the failed item\n",
    "        print(\"FAIL:\", item)\n",
    "        pass\n",
    "\n",
    "os_client.indices.refresh(index=cfg.index)\n",
    "print(f\"Bulk indexed {success} documents into {cfg.index}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4ba4649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "sampled_results = random.sample(list(results.items()), 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eacfa88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.192, 'mrr': 0.1148714285714286}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(os_client, cfg.index, dict(sampled_results), cfg=RET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a0c885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal metric\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "\n",
    "# Evaluate\n",
    "\n",
    "def evaluate(client, index, qid_to_queries: dict, *, cfg=RET):\n",
    "    total_hr = total_mrr = n = 0\n",
    "    for gold, qs in qid_to_queries.items():\n",
    "        for q in qs:\n",
    "            hits = retrieve(client, index, q, cfg=cfg)\n",
    "            ids  = ids_from_hits(hits)\n",
    "            total_hr  += hit_rate_at_k(ids, gold, cfg[\"top_k\"])\n",
    "            total_mrr += mrr_at_k(ids, gold, cfg[\"top_k\"])\n",
    "            n += 1\n",
    "    return {\"hit_rate\": total_hr / max(1,n), \"mrr\": total_mrr / max(1,n)}\n",
    "\n",
    "def calculate_metrics(ground_truth):\n",
    "    relevance_total = []\n",
    "    for i in tqdm(ground_truth):\n",
    "        query = i['query']\n",
    "        doc_id = i['doc_id']\n",
    "        hits = retrieve(os_client, cfg.index, query, cfg=RET)\n",
    "        s_ids  = ids_from_hits(hits)\n",
    "        relevance = [doc_id == s_id for s_id in s_ids]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    mrr_score = mrr(relevance_total)\n",
    "    hit_rate_score = hit_rate(relevance_total)\n",
    "\n",
    "    return {\n",
    "        \"mrr\": mrr_score,\n",
    "        \"hit_rate\": hit_rate_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "65669657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6d3fe71c6e4a1fa848af82aa063cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'mrr': 0.11047309523809525, 'hit_rate': 0.19}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(ground_truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc95be14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "content-pal-XSZEyUfq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
